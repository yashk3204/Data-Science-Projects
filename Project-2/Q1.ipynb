{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "P = list(map(float, input().split(',')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73W1sXiUB4jy",
        "outputId": "90c43f96-0d7a-4bfa-aa1e-ec329ea8270d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1,0.3,0.4,0.1,0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q = list(map(float, input().split(',')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evuB6DsOCDEl",
        "outputId": "852b62d2-a2c1-4767-87cd-7a7062c1a4b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2,0.2,0.3,0.2,0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def validate(p, q):\n",
        "  if not (np.isclose(sum(p), 1.0) and np.isclose(sum(q), 1.0)):\n",
        "    print(\"Invalid probability distributions\")\n",
        "    return False\n",
        "  if len(p) != len(q):\n",
        "    print(\"Invalid probability distributions\")\n",
        "    return False\n",
        "  for i in range(len(p)):\n",
        "    if p[i] < 0 or q[i] < 0:\n",
        "      print(\"Invalid probability distributions\")\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "yK1Z-dyOD9hU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_divergence(p, q):\n",
        "  if not validate(p, q):\n",
        "    return\n",
        "  res = 0\n",
        "  for i in range(len(p)):\n",
        "      if p[i] != 0 and q[i] != 0:\n",
        "          res += p[i] * np.log2(p[i] / q[i])\n",
        "  return round(res, 4)"
      ],
      "metadata": {
        "id": "0ebx7U53NxSF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use base 2 in information theory where KL divergence is measured in bits.\n",
        "If we use base e, it is measured in nats."
      ],
      "metadata": {
        "id": "BLZ-XbteQ6Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kl_divergence(P, Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JmGeuF-OChb",
        "outputId": "fd314011-05f4-4ad6-f763-8f3405a200c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1415"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KL divergence is defined as the number of bits required to convert one distribution into another."
      ],
      "metadata": {
        "id": "6Ys56r7ZGEFw"
      }
    }
  ]
}